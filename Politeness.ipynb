{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import cPickle\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.sparse import csr_matrix\n",
    "import sklearn\n",
    "import nltk\n",
    "from features.vectorizer import PolitenessFeatureVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MODEL_FILENAME = 'politeness-svm.p'\n",
    "clf = cPickle.load(open(MODEL_FILENAME))\n",
    "vectorizer = PolitenessFeatureVectorizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(request):\n",
    "    \"\"\"\n",
    "    :param request - The request document to score\n",
    "    :type request - dict with 'sentences' and 'parses' field\n",
    "        sample (taken from test_documents.py)--\n",
    "        {\n",
    "            'sentences': [\n",
    "                \"Have you found the answer for your question?\", \n",
    "                \"If yes would you please share it?\"\n",
    "            ],\n",
    "            'parses': [\n",
    "                [\"csubj(found-3, Have-1)\", \"dobj(Have-1, you-2)\", \"root(ROOT-0, found-3)\", \"det(answer-5, the-4)\", \"dobj(found-3, answer-5)\", \"poss(question-8, your-7)\", \"prep_for(found-3, question-8)\"], \n",
    "                [\"prep_if(would-3, yes-2)\", \"root(ROOT-0, would-3)\", \"nsubj(would-3, you-4)\", \"ccomp(would-3, please-5)\", \"nsubj(it-7, share-6)\", \"xcomp(please-5, it-7)\"]\n",
    "            ]\n",
    "        } \n",
    "\n",
    "    returns class probabilities as a dict\n",
    "        {\n",
    "            'polite': float, \n",
    "            'impolite': float\n",
    "        }\n",
    "    \"\"\"\n",
    "    # vectorizer returns {feature-name: value} dict\n",
    "    features = vectorizer.features(request)\n",
    "    fv = [features[f] for f in sorted(features.iterkeys())]\n",
    "    # Single-row sparse matrix\n",
    "    X = csr_matrix(np.asarray([fv]))\n",
    "    print clf\n",
    "    print X\n",
    "    probs = clf.predict_proba(X)\n",
    "    # Massage return format\n",
    "    probs = {\"polite\": probs[0][1], \"impolite\": probs[0][0]}\n",
    "    return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.02, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
      "  kernel='linear', max_iter=-1, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "  (0, 115)\t1\n",
      "  (0, 266)\t1\n",
      "  (0, 343)\t1\n",
      "  (0, 452)\t1\n",
      "  (0, 501)\t1\n",
      "  (0, 640)\t1\n",
      "  (0, 675)\t1\n",
      "  (0, 695)\t1\n",
      "  (0, 731)\t1\n",
      "  (0, 745)\t1\n",
      "  (0, 748)\t1\n",
      "  (0, 812)\t1\n",
      "  (0, 956)\t1\n",
      "  (0, 959)\t1\n",
      "  (0, 1020)\t1\n",
      "  (0, 1135)\t1\n",
      "  (0, 1154)\t1\n",
      "  (0, 1259)\t1\n",
      "  (0, 1344)\t1\n",
      "  (0, 1350)\t1\n",
      "  (0, 1352)\t1\n",
      "  (0, 1353)\t1\n",
      "  (0, 1360)\t1\n",
      "  (0, 1375)\t1\n",
      "  (0, 1377)\t1\n",
      "====================\n",
      "Text:  Have you found the answer for your question? If yes would you please share it?\n",
      "\tP(polite) = 0.719\n",
      "\tP(impolite) = 0.281\n",
      "\n",
      "\n",
      "SVC(C=0.02, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
      "  kernel='linear', max_iter=-1, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "  (0, 27)\t1\n",
      "  (0, 95)\t1\n",
      "  (0, 337)\t1\n",
      "  (0, 591)\t1\n",
      "  (0, 696)\t1\n",
      "  (0, 710)\t1\n",
      "  (0, 726)\t1\n",
      "  (0, 731)\t1\n",
      "  (0, 747)\t1\n",
      "  (0, 761)\t1\n",
      "  (0, 811)\t1\n",
      "  (0, 1018)\t1\n",
      "  (0, 1246)\t1\n",
      "  (0, 1259)\t1\n",
      "  (0, 1263)\t1\n",
      "  (0, 1280)\t1\n",
      "  (0, 1308)\t1\n",
      "  (0, 1311)\t1\n",
      "  (0, 1357)\t1\n",
      "====================\n",
      "Text:  Sorry :) I dont want to hack the system!! :) is there another way?\n",
      "\tP(polite) = 0.640\n",
      "\tP(impolite) = 0.360\n",
      "\n",
      "\n",
      "SVC(C=0.02, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
      "  kernel='linear', max_iter=-1, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "  (0, 1)\t1\n",
      "  (0, 26)\t1\n",
      "  (0, 139)\t1\n",
      "  (0, 198)\t1\n",
      "  (0, 228)\t1\n",
      "  (0, 241)\t1\n",
      "  (0, 560)\t1\n",
      "  (0, 580)\t1\n",
      "  (0, 666)\t1\n",
      "  (0, 687)\t1\n",
      "  (0, 701)\t1\n",
      "  (0, 731)\t1\n",
      "  (0, 768)\t1\n",
      "  (0, 772)\t1\n",
      "  (0, 823)\t1\n",
      "  (0, 856)\t1\n",
      "  (0, 914)\t1\n",
      "  (0, 1024)\t1\n",
      "  (0, 1082)\t1\n",
      "  (0, 1259)\t1\n",
      "  (0, 1280)\t1\n",
      "  (0, 1288)\t1\n",
      "  (0, 1352)\t1\n",
      "  (0, 1360)\t1\n",
      "  (0, 1364)\t1\n",
      "====================\n",
      "Text:  What are you trying to do?  Why can't you just store the \"Range\"?\n",
      "\tP(polite) = 0.034\n",
      "\tP(impolite) = 0.966\n",
      "\n",
      "\n",
      "SVC(C=0.02, cache_size=200, class_weight=None, coef0=0.0, degree=3, gamma=0.0,\n",
      "  kernel='linear', max_iter=-1, probability=True, random_state=None,\n",
      "  shrinking=True, tol=0.001, verbose=False)\n",
      "  (0, 17)\t1\n",
      "  (0, 32)\t1\n",
      "  (0, 33)\t1\n",
      "  (0, 106)\t1\n",
      "  (0, 272)\t1\n",
      "  (0, 278)\t1\n",
      "  (0, 379)\t1\n",
      "  (0, 475)\t1\n",
      "  (0, 553)\t1\n",
      "  (0, 563)\t1\n",
      "  (0, 585)\t1\n",
      "  (0, 592)\t1\n",
      "  (0, 700)\t1\n",
      "  (0, 715)\t1\n",
      "  (0, 727)\t1\n",
      "  (0, 731)\t1\n",
      "  (0, 840)\t1\n",
      "  (0, 975)\t1\n",
      "  (0, 982)\t1\n",
      "  (0, 1020)\t1\n",
      "  (0, 1050)\t1\n",
      "  (0, 1076)\t1\n",
      "  (0, 1082)\t1\n",
      "  (0, 1244)\t1\n",
      "  (0, 1259)\t1\n",
      "  (0, 1270)\t1\n",
      "  (0, 1280)\t1\n",
      "  (0, 1294)\t1\n",
      "  (0, 1310)\t1\n",
      "  (0, 1327)\t1\n",
      "  (0, 1364)\t1\n",
      "====================\n",
      "Text:  This was supposed to have been moved to &lt;url&gt; per the cfd. why wasn't it moved?\n",
      "\tP(polite) = 0.068\n",
      "\tP(impolite) = 0.932\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshat/tem/computational-politeness/env/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2499: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  VisibleDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    \"\"\"\n",
    "    Sample classification of requests\n",
    "    \"\"\"\n",
    "\n",
    "    from test_documents import TEST_DOCUMENTS\n",
    "\n",
    "    for doc in TEST_DOCUMENTS:\n",
    "\n",
    "        probs = score(doc)\n",
    "\n",
    "        print \"====================\"\n",
    "        print \"Text: \", doc['text']\n",
    "        print \"\\tP(polite) = %.3f\" % probs['polite']\n",
    "        print \"\\tP(impolite) = %.3f\" % probs['impolite']\n",
    "        print \"\\n\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "packages2versions = [(\"scikit-learn\", sklearn, \"0.15.1\"), (\"numpy\", np, \"1.9.0\"), (\"nltk\", nltk, \"3.0.0\"), (\"scipy\", scipy, \"0.12.0\")]\n",
    "\n",
    "for name, package, expected_v in packages2versions:\n",
    "    if package.__version__ < expected_v:\n",
    "        print(\"Warning: package '%s', expected version >= %s, detected %s. Code functionality not guaranteed.\\n\" % (name, expected_v, package.__version__))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unigrams=cPickle.load(open(\"features/featunigrams.p\"))\n",
    "\n",
    "aks=\"I am not a great person, hahaha\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'not', 'a', 'great', 'person', ',', 'hahaha']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(aks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_filename=\"features/liu-positive-words.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_words = set(map(lambda x: x.strip(), open(pos_filename).read().splitlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "has_positive = lambda l: len(positive_words.intersection(l)) > 0\n",
    "has_positive.__name__ = \"HASPOSITIVE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.115403712172\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "filename='stack-exchange.annotated.csv'\n",
    "f = open(filename)\n",
    "csv_f = csv.reader(f)\n",
    "from nltk import word_tokenize\n",
    "vals=[]\n",
    "i=0\n",
    "csv_f.next()\n",
    "# for rows in csv_f:\n",
    "#     #print word_tokenize(rows[2])\n",
    "#     try:\n",
    "#         if len(positive_words.intersection(word_tokenize(rows[2]))) > 0:\n",
    "#             vals.append(float(rows[-1]))\n",
    "#     except:\n",
    "#         print rows[2]\n",
    "filename='wikipedia.annotated.csv'\n",
    "f = open(filename)\n",
    "csv_f = csv.reader(f)\n",
    "for rows in csv_f:\n",
    "    #print word_tokenize(rows[2])\n",
    "    try:\n",
    "        l=[x.lower() for x in word_tokenize(rows[2])]\n",
    "        if len(positive_words.intersection(l)) > 0:\n",
    "            vals.append(float(rows[-1]))\n",
    "    except:\n",
    "        print rows[2]\n",
    "#     i+=1\n",
    "#     if i> 100:\n",
    "#         break\n",
    "    \n",
    "                  \n",
    "print sum(vals)/len(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_table():\n",
    "    # file_name=\n",
    "    # matrix=[]\n",
    "    # vals=[]\n",
    "    # documents=pickle.load(open(file_name))\n",
    "    # for vals in documents:\n",
    "    #     matrix.append(get_politeness_strategy_features(vals))\n",
    "    #     scores.append(vals[scores])\n",
    "    matrix=[[1, 0, 0], [1,1,0], [0,0,1], [1,1,1]]\n",
    "    scores=[2.,1.,4., -1.]\n",
    "    matrix=np.array(matrix)\n",
    "    scores=np.array(scores)\n",
    "    mult=np.multiply(matrix.T, scores.T).T\n",
    "    mult=np.sum(mult, axis=0)\n",
    "    total=np.sum(matrix, axis=0)\n",
    "    results=np.divide(mult, total)\n",
    "    results=results.tolist()\n",
    "    POLITENESS_FEATURES=[\"1\", \"2\", \"3\"]\n",
    "    for i, f in enumerate(POLITENESS_FEATURES):\n",
    "        print f,  results[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.666666666667\n",
      "2 0.0\n",
      "3 1.5\n"
     ]
    }
   ],
   "source": [
    "generate_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "filename=\"wikipedia.annotated.csv\"\n",
    "\n",
    "f = open(filename)\n",
    "csv_f = csv.reader(f)\n",
    "text_corpus=[]\n",
    "csv_f.next()\n",
    "for row in csv_f:\n",
    "    text_corpus.append((row[2],float(row[-1])))\n",
    "text_corpus.sort(key=lambda l: l[1], reverse=True)\n",
    "top=[]\n",
    "for i in range(len(text_corpus)/4):\n",
    "    top.append(text_corpus[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.311945748565\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "vals=[]\n",
    "for rows in top:\n",
    "    #print word_tokenize(rows[2])\n",
    "    #print rows[1]\n",
    "    try:\n",
    "        l=[x.lower() for x in word_tokenize(rows[0])]\n",
    "        if len(positive_words.intersection(l)) > 0:\n",
    "            vals.append(float(rows[-1]))\n",
    "    except:\n",
    "        print rows[0]\n",
    "#     i+=1\n",
    "#     if i> 100:\n",
    "#         break\n",
    "a=len(vals)\n",
    "vals=[]\n",
    "for rows in text_corpus:\n",
    "    #print word_tokenize(rows[2])\n",
    "    #print rows[1]\n",
    "    try:\n",
    "        l=[x.lower() for x in word_tokenize(rows[0])]\n",
    "        if len(positive_words.intersection(l)) > 0:\n",
    "            vals.append(float(rows[-1]))\n",
    "    except:\n",
    "        print rows[0] \n",
    "b=len(vals)\n",
    "# print len(vals)/float(len(top))        \n",
    "# print sum(vals)/len(vals)\n",
    "print a/float(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
